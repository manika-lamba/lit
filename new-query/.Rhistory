install.packages("handcodeR", force = TRUE)
library(handcodeR)
if(!require(pacman)) install.packages("pacman")
install.packages("pacman")
pacman::p_load(archiveRetriever,
stringr)
# Use the archiveRetriever to download article
nytimes_article <- scrape_urls(Urls = "http://web.archive.org/web/20201001004918/https://www.nytimes.com/2020/09/30/opinion/biden-trump-2020-debate.html",
Paths = c(title = "//h1[@itemprop='headline']",
author = "//span[@itemprop='name']",
date = "//time//text()",
article = "//section[@itemprop='articleBody']//p"))
# Split up the article in different sentences
sentences <- unlist(str_split(nytimes_article$article, pattern = "(?<=\\.)\\s"))
head(sentences)
annotated <- handcode(data = sentences,
candidate = c("Joe Biden", "Donald Trump"),
sentiment = c("positive", "negative"))
View(annotated)
install.packages("revtools")
library (revtools)
library(revtools)
## titles
result_titles <- screen_titles()
# read file
data <- read_bibliography("merged.csv")
setwd("/Users/manika/Desktop/Github/lit/new-query")
# read file
data <- read_bibliography("merged.csv")
## find duplicates
duplicates <- screen_duplicates(data)
## titles
result_titles <- screen_titles(data)
Q<-mergeDbSources(M,P,remove.duplicated=TRUE)
library (revtools)
library(RefManageR)
library(bibliometrix)
library(bibtex)
file <- "wos.bib"
M <- convert2df(file, dbsource = "wos", format = "bibtex")
# load pubmed file
pubmed <- "pubmed.txt"
P <- convert2df(pubmed, dbsource = "pubmed", format = "pubmed")
Q<-mergeDbSources(M,P,remove.duplicated=TRUE)
View(Q)
library (revtools)
library(RefManageR)
library(bibliometrix)
library(bibtex)
wos_bib <- ReadBib("wos.bib")
pub_bib <- ReadBib("pubmed.bib")
merged_bib <- c(wos_bib, pub_bib)
unique_bib <- unique(merge, by = "DOI")
unique_bib <- unique(merge, by = "DOI")
unique_bib <- unique(merged_bib, by = "DOI")
WriteBib(unique_bib, file = "merged_and_deduplicated2.bib")
# read file
data <- read_bibliography("merged_and_deduplicated2.bib")
setwd("/Users/manika/Desktop/Github/lit/new-query")
# read file
data <- read_bibliography("merged.bib")
WriteBib(unique_bib, file = "merged.bib")
# read file
data <- read_bibliography("merged.bib")
# Define your input string
z <- "   QUIROGA S....<81>NCHEZ, ENEDINA/ABE-9443-2021"
# Function to remove special characters
remove_special_chars <- function(text) {
# Try to remove special characters using gsub
result <- tryCatch(
gsub("<[[:alnum:]]{2}>", "", text),
error = function(e) {
# Print error message
cat("Error:", e$message, "\n")
# Return the original text if there's an error
return(text)
}
)
# Return the result
return(result)
}
# Remove special characters from the input string
cleaned_z <- remove_special_chars(z)
# Define your input string
z <- merged_bib
# Function to remove special characters
remove_special_chars <- function(text) {
# Try to remove special characters using gsub
result <- tryCatch(
gsub("<[[:alnum:]]{2}>", "", text),
error = function(e) {
# Print error message
cat("Error:", e$message, "\n")
# Return the original text if there's an error
return(text)
}
)
# Return the result
return(result)
}
# Remove special characters from the input string
cleaned_z <- remove_special_chars(z)
file_path <- "cleaned_reference.bib"
# Write the cleaned_z to the BibTeX file
writeLines(cleaned_z, file_path)
# Print message indicating successful write
cat("BibTeX file saved successfully:", file_path, "\n")
# read file
data <- read_bibliography("cleaned_reference.bib")
# read file
data <- read_bibliography("cleaned_reference.bib")
# Define your input string
z <- merged_bib
# Function to remove non-ASCII characters
remove_non_ascii <- function(text) {
# Remove non-ASCII characters using iconv
cleaned_text <- iconv(text, to = "ASCII", sub = " ")
return(cleaned_text)
}
# Define your input string
z <- "   QUIROGA S....<81>NCHEZ, ENEDINA/ABE-9443-2021"
# Remove non-ASCII characters from the input string
cleaned_z <- remove_non_ascii(z)
# Define the file path for saving the BibTeX file
file_path <- "cleaned_references.bib"
# Write the cleaned_z to the BibTeX file
writeLines(cleaned_z, file_path)
# Print message indicating successful write
cat("BibTeX file saved successfully:", file_path, "\n")
# read file
data <- read_bibliography("cleaned_reference.bib")
WriteBib(unique_bib, file = "merged.bib")
# read file
data <- read_bibliography("merged.bib")
# read file
data <- read_bibliography("merged.bib")
# read file
data <- read_bibliography("merged.bib")
# read file
data <- read_bibliography("merged.bib")
# read file
data <- read_bibliography("merged.bib")
# read file
data <- read_bibliography("merged.bib")
## find duplicates
duplicates <- screen_duplicates(data)
## find duplicates
duplicates <- screen_duplicates()
## find duplicates
duplicates <- screen_duplicates()
## asbtracts
result_abstracts <- screen_abstracts("cleaned_merged2.csv")
## asbtracts
result_abstracts <- screen_abstracts()
# distribute tasks
task <- distribute_tasks(data,reviewers,write_csv=TRUE, file_name="reviewer.csv",return_data=FALSE)
## titles
result_titles <- screen_titles()
x <- 'cleaned_merged2.csv'
x <- cleaned_merged2.csv
result<-distribute_tasks(x, 4,write_csv=FALSE)#splitevenlyamong4reviewers
x <- read_csv("cleaned_merged2.csv")
x <- read.bib("cleaned_merged2.csv")
x <- read_bibliography("cleaned_merged2.csv")
result<-distribute_tasks(x, 4,write_csv=FALSE)#splitevenlyamong4reviewers
result <- distribute_tasks(x, 4, write_csv=TRUE)#splitevenlyamong4reviewers
