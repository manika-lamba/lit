install.packages("handcodeR", force = TRUE)
library(handcodeR)
if(!require(pacman)) install.packages("pacman")
install.packages("pacman")
pacman::p_load(archiveRetriever,
stringr)
# Use the archiveRetriever to download article
nytimes_article <- scrape_urls(Urls = "http://web.archive.org/web/20201001004918/https://www.nytimes.com/2020/09/30/opinion/biden-trump-2020-debate.html",
Paths = c(title = "//h1[@itemprop='headline']",
author = "//span[@itemprop='name']",
date = "//time//text()",
article = "//section[@itemprop='articleBody']//p"))
# Split up the article in different sentences
sentences <- unlist(str_split(nytimes_article$article, pattern = "(?<=\\.)\\s"))
head(sentences)
annotated <- handcode(data = sentences,
candidate = c("Joe Biden", "Donald Trump"),
sentiment = c("positive", "negative"))
View(annotated)
install.packages("revtools")
library (revtools)
library(biblioshiny)
install.packages("bibliometrix")
library(bibliometrix)
biblioshiny()
setwd("/Users/manika/Desktop/Github/lit")
pubmed <- "https://raw.githubusercontent.com/manika-lamba/lit/main/new-query/pubmed.txt"
library (revtools)
library(RefManageR)
library(bibliometrix)
M <- convert2df(file, dbsource = "pubmed", format = "pubmed")
M <- convert2df(pubmed, dbsource = "pubmed", format = "pubmed")
pubmed <- "https://raw.githubusercontent.com/manika-lamba/lit/main/new-query/pubmed.txt"
M <- convert2df(pubmed, dbsource = "pubmed", format = "pubmed")
# Load required library
library(dplyr)
# Read the Web of Science file in BibTeX format
wos_df <- read.bib("wos.bib")
setwd("/Users/manika/Desktop/Github/lit/new-query")
# Read the Web of Science file in BibTeX format
wos_df <- read.bib("wos.bib")
# Read the Web of Science file in BibTeX format
wos_df <- read.bib("/wos.bib")
# Read the Web of Science file in BibTeX format
wos_df <- read.bib("/Users/manika/Desktop/Github/lit/new-query/wos.bib")
library(RefManageR)
# Read the Web of Science file in BibTeX format
wos_df <- read.bib("/Users/manika/Desktop/Github/lit/new-query/wos.bib")
library(dplyr)
library(RefManageR)
library (revtools)
library(bibliometrix)
# Read the Web of Science file in BibTeX format
wos_df <- ReadBib("/Users/manika/Desktop/Github/lit/new-query/wos.bib")
# Read the PubMed file in CSV format
pubmed_df <- read.csv("pubmed.csv", stringsAsFactors = FALSE)
wos_data <- convert2df("wos_df")
wos_data <- convert2df(""/Users/manika/Desktop/Github/lit/new-query/wos.bib")
wos_data <- convert2df(/Users/manika/Desktop/Github/lit/new-query/wos.bib")
wos_data <- convert2df("/Users/manika/Desktop/Github/lit/new-query/wos.bib")
wos_data <- ReadBib("/Users/manika/Desktop/Github/lit/new-query/wos.bib")
# Read the PubMed file in CSV format
pubmed_data <- read.csv("pubmed.csv", stringsAsFactors = FALSE)
# Read the PubMed file in CSV format
pubmed_data <- read.csv("pubmed.txt", stringsAsFactors = FALSE)
View(pubmed_data)
# Read the PubMed file in CSV format
pubmed_data <- read.csv("pubmed.csv", stringsAsFactors = FALSE)
View(pubmed_data)
# Convert DOI or PMID to character to ensure consistency
wos_data$DOI <- as.character(wos_data$DOI)
pubmed_data$PMID <- as.character(pubmed_data$PMID)
# Merge the two datasets based on common identifier (DOI or PMID)
merged_data <- merge(wos_data, pubmed_data, by.x = "DOI", by.y = "PMID", all = TRUE)
# Merge the two datasets based on common identifier (DOI or PMID)
tryCatch({
merged_data <- merge(wos_data, pubmed_data, by.x = "DOI", by.y = "PMID", all = TRUE)
}, error = function(e) {
print("Error occurred during merge:")
print(e)
})
# Check for any missing values after the merge
if (any(is.na(merged_data$DOI)) || any(is.na(merged_data$PMID))) {
print("Warning: Missing values detected after merge.")
}
# Merge the two datasets based on common identifier (DOI or PMID)
merged_data <- merge(wos_data, pubmed_data, by.x = "DOI", by.y = "PMID", all = TRUE)
# Merge the two datasets based on common identifier (DOI or PMID)
tryCatch({
merged_data <- merge(wos_data, pubmed_data, by.x = "DOI", by.y = "PMID", all = TRUE)
}, error = function(e) {
print("Error occurred during merge:")
print(e)
})
# Check for any missing values after the merge
if (any(is.na(merged_data$DOI)) || any(is.na(merged_data$PMID))) {
print("Warning: Missing values detected after merge.")
}
# Convert the merged data frame to a BibEntry object
merged_bib <- as.BibEntry(merged_data)
# Merge the two datasets based on common identifier (DOI or PMID)
merged_data <- merge(wos_data, pubmed_data, by.x = "DOI", by.y = "PMID", all = TRUE)
# Merge the two datasets based on common identifier (DOI or PMID)
tryCatch({
merged_data <- merge(wos_data, pubmed_data, by.x = "DOI", by.y = "PMID", all = TRUE)
}, error = function(e) {
print("Error occurred during merge:")
print(e)
})
# Check for any missing values after the merge
if (any(is.na(merged_data$DOI)) || any(is.na(merged_data$PMID))) {
print("Warning: Missing values detected after merge.")
}
# Check if merged_data is NULL
if (is.null(merged_data)) {
} else {
# Convert the merged data frame to a BibEntry object
merged_bib <- as.BibEntry(merged_data)
# Convert the merged data frame to a BibEntry object
merged_bib <- as.BibEntry(merged_data)
# Deduplicate based on DOI or PMID
deduplicated_bib <- unique(merged_bib)
tryCatch({
merged_data <- merge(wos_data, pubmed_data, by.x = "DOI", by.y = "PMID", all = TRUE)
}, error = function(e) {
print("Error occurred during merge:")
print(e)
merged_data <- NULL  # Assigning NULL to merged_data to ensure it exists
})
if (is.null(merged_data)) {
print("Merge was unsuccessful. Exiting script.")
} else {
# Convert the merged data frame to a BibEntry object
merged_bib <- as.BibEntry(merged_data)
# Convert the merged data frame to a BibEntry object
merged_bib <- as.BibEntry(merged_data)
# Deduplicate based on DOI or PMID
deduplicated_bib <- unique(merged_bib)
# Convert the merged data frame to a BibEntry object
merged_bib <- as.BibEntry(merged_data)
# Deduplicate based on DOI or PMID
deduplicated_bib <- unique(merged_bib)
# Write the deduplicated merged dataset to a new BibTeX file
write.bib(deduplicated_bib, file = "merged_deduplicated_data.bib")
if (is.null(merged_data)) {
print("Merge was unsuccessful. Exiting script.")
} else {
# Convert the merged data frame to a BibEntry object
merged_bib <- as.BibEntry(merged_data)
# Deduplicate based on DOI or PMID
deduplicated_bib <- unique(merged_bib)
# Write the deduplicated merged dataset to a new BibTeX file
write.bib(deduplicated_bib, file = "merged_deduplicated_data.bib")
}
# Merge the two datasets based on common identifier (DOI or PMID)
merged_data <- merge(wos_data, pubmed_data, by.x = "DOI", by.y = "PMID", all = TRUE)
merged_data <- merge(wos_data, pubmed_data, by.x = "DOI", by.y = "PMID", all = TRUE)
# Attempt to merge the two datasets based on common identifier (DOI or PMID)
tryCatch({
merged_data <- merge(wos_data, pubmed_data, by.x = "DOI", by.y = "PMID", all = TRUE)
}, error = function(e) {
print("Error occurred during merge:")
print(e)
merged_data <- NULL  # Assigning NULL to merged_data to ensure it exists
})
if (is.null(merged_data)) {
print("Merge was unsuccessful. Exiting script.")
} else {
# Convert merged_data to a BibEntry object
merged_bib <- toBibEntry(merged_data)
# Deduplicate based on DOI or PMID
deduplicated_bib <- unique(merged_bib)
# Write the deduplicated merged dataset to a new BibTeX file
write.bib(deduplicated_bib, file = "merged_deduplicated_data.bib")
}
# Merge the two datasets based on common identifier (DOI or PMID)
merged_data <- merge(wos_data, pubmed_data, by.x = "DOI", by.y = "PMID", all = TRUE)
# Convert DOI or PMID to character to ensure consistency
wos_data$DOI <- as.character(wos_data$DOI)
pubmed_data$PMID <- as.character(pubmed_data$PMID)
# Merge the two datasets based on common identifier (DOI or PMID)
merged_data <- merge(wos_data, pubmed_data, by.x = "DOI", by.y = "PMID", all = TRUE)
wos_bib <- ReadBib("savedrecs.bib")
pubmed <- "https://raw.githubusercontent.com/manika-lamba/lit/main/new-query/pubmed.txt"
M <- convert2df(pubmed, dbsource = "pubmed", format = "pubmed")
library (revtools)
library(RefManageR)
library(bibliometrix)
wos_bib <- ReadBib("wos.bib")
pubmed <- "https://raw.githubusercontent.com/manika-lamba/lit/main/new-query/pubmed.txt"
M <- convert2df(pubmed, dbsource = "pubmed", format = "pubmed")
pubmed <- "https://raw.githubusercontent.com/manika-lamba/lit/main/new-query/pubmed.txt"
M <- convert2df(pubmed, dbsource = "pubmed", format = "pubmed")
head(M["TC"])
file <- "wos.bib"
M <- convert2df(file, dbsource = "wos", format = "bibtex")
head(M["TC"])
pubmed <- "pubmed.txt"
P <- convert2df(pubmed, dbsource = "pubmed", format = "pubmed")
head(M["TC"])
merge <- c(M, P)
# Remove duplicates based on DOI (assuming DOI is present in both .bib files)
unique_bib <- unique(merge, by = "DOI")
# Write the merged and deduplicated .bib file
WriteBib(unique_bib, file = "merged_and_deduplicated2.bib")
View(unique_bib)
Q<-mergeDbSources(M,P,remove.duplicated=TRUE)
dim(Q)
# Write the merged and deduplicated .bib file
WriteBib(Q, file = "merged_and_deduplicated2.bib")
View(Q)
View(Q)
write.bib(merged_data, file = output_file)
library(bibliometrix)
write.bib(merged_data, file = output_file)
write.bib(Q, file = output_file)
writeFiles(Q, file = output_file)
library(bibtex)
WriteBib(file = "Q", bib)
View(Q)
# Create a BibTeX object
bib <- BibEntry()
# Add entries to the BibTeX object
for (i in 1:nrow(Q)) {
bib <- AddBibEntry(bib,
type = "article",
key = paste0("entry", i),
fields = list(
author = Q$author[i],
title = Q$title[i],
year = Q$year[i]
# Add other fields as necessary
))
}
# Write the BibTeX data to a file
WriteBib(file = "Q.bib", bib)
# read file
data <- read_bibliography("Q")
Q<-mergeDbSources(M,P,remove.duplicated=TRUE)
# read file
data <- read_bibliography("Q")
# read file
data <- read_bibliography("Q.bib")
# Convert your dataframe to a BibEntry object
bib_entries <- BibEntry(
type = "misc",
key = "Q",
fields = lapply(Q, as.character)
)
write.csv(Q, "merged.csv")
View(wos_data)
View(M)
